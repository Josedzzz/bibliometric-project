@ARTICLE{9020189,
  author={Lin, Pei-Hsuan and Chen, Shih-Yeh},
  journal={IEEE Access}, 
  title={Design and Evaluation of a Deep Learning Recommendation Based Augmented Reality System for Teaching Programming and Computational Thinking}, 
  year={2020},
  volume={8},
  number={},
  pages={45689-45699},
  abstract={Programming is considered a skill to arouse and inspire learner's potential. Learning to program is a complex process that requires students to write grammar and instructions. The structure of a programming language does not cause impose problems to students, the real obstacle is how to apply these learned grammars and present them in a complete and correct program code for problem solving. In this study, a deep learning recommendation system was developed, which includes augmented reality (AR) technology, and learning theory, and is provided for study by students in non-major and also from different learning backgrounds. Those students divided into two groups, the students participating in the experimental group were using the AR system with deep learning recommendation and the students participating in the control group were using the AR system without deep learning recommendation. The results show that students in experimental group perform better than the control group with regards to learning achievement. On the other hand, in the part of computational thinking ability, students using a deep learning recommendation based AR system is significantly better than those using non-deep learning recommendation based AR system. Among the various dimensions of computational thinking, creativity, logical computing, critical thinking, and problem-solving skills are significantly different among the two groups of students. The students in experimental group perform better than the control group with regards to the dimensions of computational thinking, creativity, logical computing, critical thinking, and problem-solving skills.},
  keywords={Machine learning;Education;Programming profession;Problem-solving;Grammar;Augmented reality;Deep learning recommendation;computational thinking;AR technology},
  doi={10.1109/ACCESS.2020.2977679},
  ISSN={2169-3536},
  month={},}@ARTICLE{9172001,
  author={Demartini, Claudio Giovanni and Benussi, Lorenzo and Gatteschi, Valentina and Renga, Flavio},
  journal={IEEE Access}, 
  title={Education and Digital Transformation: The “Riconnessioni” Project}, 
  year={2020},
  volume={8},
  number={},
  pages={186233-186256},
  abstract={Schools, universities, and other educational entities are increasingly aware of the untapped potential of digital transformation, an essential process for increasing efficiency and collaboration, and reducing costs and errors in the management of at-scale training systems. In this context, the “Riconnessioni” project was promoted by the Compagnia di San Paolo in agreement with the Ministry of Education but planned, started and developed by the Foundation for the School. The digital transformation started with a defined strategy that leveraged opportunities presented by new technology while meeting the objectives of system stakeholders. Through several steps, that strategy was developed for education connecting everything to support tomorrow’s digital world and creating strong strategic partnerships able to build an ecosystem connecting people, processes, and things into a powerful, secure, and smart communications network. This paper reports on the three-year Riconnessioni project, which is combining the energies of teachers, managers, administrative staff, students, among others, and experimenting with new learning models, taking advantage of opportunities that emerged from perceptions stemming from concerns and systemic issues. To date, more than 150 schools in Italy have been included in the project, together with 550 teachers selected to scale up the instructional process. Using a methodology called “cascade training”, the 550 selected teachers were able to spread the knowledge to more than 2,600 colleagues. The monitoring and evaluation activity performed in Riconnessioni aims at processing information on implementation and results, following three lines. First, it regularly evaluates project activities from a reporting standpoint. Second, it verifies the plan consistency against implementation achievements. Third, it identifies changes produced and focuses on teachers’ and students’ skills to evaluate the effects of the project. The assessment framework is also discussed in this work, reporting on results regarding feedback, follow-up, and effects gathered from the field. The evaluation highlighted that labs were indeed able to improve teachers’ competence and underlined the added value of cascade training which spread digital domain knowledge and awareness into the group of involved schools.},
  keywords={Digital transformation;Training;Biological system modeling;Business;Cloud computing;Collaboration;Digital transformation;adaptive learning;computational thinking;computer science;education;information technologies;primary school;secondary school},
  doi={10.1109/ACCESS.2020.3018189},
  ISSN={2169-3536},
  month={},}@ARTICLE{5613437,
  author={Liu, Zhicheng and Stasko, John},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective}, 
  year={2010},
  volume={16},
  number={6},
  pages={999-1008},
  abstract={Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development},
  keywords={Cognitive science;Cognition;Visualization;Data visualization;Computational modeling;Brain modeling;Humans;mental model;model-based reasoning;distributed cognition;interaction;theory;information visualization},
  doi={10.1109/TVCG.2010.177},
  ISSN={1941-0506},
  month={Nov},}@ARTICLE{10681094,
  author={Ahmed, Zishan and Shanto, Shakib Sadat and Rime, Most. Humayra Khanom and Morol, Md. Kishor and Fahad, Nafiz and Hossen, Md. Jakir and Abdullah-Al-Jubair, Md.},
  journal={IEEE Access}, 
  title={The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception}, 
  year={2024},
  volume={12},
  number={},
  pages={147023-147050},
  abstract={Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.},
  keywords={Education;Generative AI;Artificial intelligence;Surveys;Chatbots;Ethics;Market research;Chatbots;education;generative AI;opportunities and challenges;student perception},
  doi={10.1109/ACCESS.2024.3461874},
  ISSN={2169-3536},
  month={},}@ARTICLE{6389686,
  author={Schreck, Tobias and Keim, Daniel},
  journal={Computer}, 
  title={Visual Analysis of Social Media Data}, 
  year={2013},
  volume={46},
  number={5},
  pages={68-75},
  abstract={The application of visual analytics, which combines the advantages of computational knowledge discovery and interactive visualization, to social media data highlights the many benefits of this integrated approach. The Web extra at http://youtu.be/nhoq71gqyXE is a video demonstrating a prototype system for visual-interactive analysis of large georeferenced microblog datasets, describing the design of the system, and detailing its application to the VAST 2011 Challenge dataset. The dataset models an epidemic outbreak in a fictitious metropolitan area. The video shows how the system can detect the epidemic and analyze its development over time. The system was implemented by Juri Buchmueller, Fabian Maass, Stephan Sellien, Florian Stoffel, and Matthias Zieker at the University of Konstanz (they also produced this video). Further information on the system and the VAST challenge dataset can be found in E. Bertini et al., "Visual Analytics of Terrorist Activities Related to Epidemics," Proc. IEEE Conf. Visual Analytics Science and Technology (VAST 11), IEEE CS, pp. 329-330, 2011.},
  keywords={Media;Data visualization;Visual analytics;Data analysis;Data mining;Social network services;visual analytics;knowledge discovery;interactive data visualization;social media;text visualization;complex data},
  doi={10.1109/MC.2012.430},
  ISSN={1558-0814},
  month={May},}@ARTICLE{6843352,
  author={Fatemi, Mehdi and Haykin, Simon},
  journal={IEEE Access}, 
  title={Cognitive Control: Theory and Application}, 
  year={2014},
  volume={2},
  number={},
  pages={698-710},
  abstract={From an engineering point-of-view, cognitive control is inspired by the prefrontal cortex of the human brain; cognitive control may therefore be viewed as the overarching function of a cognitive dynamic system. In this paper, we describe a new way of thinking about cognitive control that embodies two basic components: learning and planning, both of which are based on two notions: 1) two-state model of the environment and the perceptor and 2) perception-action cycle, which is a distinctive characteristic of the cognitive dynamic system. Most importantly, it is shown that the cognitive control learning algorithm is a special form of Bellman's dynamic programming. Distinctive properties of the new algorithm include the following: 1) optimality of performance; 2) algorithmic convergence to optimal policy; and 3) linear law of complexity measured in terms of the number of actions taken by the cognitive controller on the environment. To validate these intrinsic properties of the algorithm, a computational experiment is presented, which involves a cognitive tracking radar that is known to closely mimic the visual brain. The experiment illustrates two different scenarios: 1) the impact of planning on learning curves of the new cognitive controller and 2) comparison of the learning curves of three different controllers, based on dynamic optimization, traditional  \(Q\) -learning, and the new algorithm. The latter two algorithms are based on the two-state model, and they both involve the use of planning.},
  keywords={Cognition;Heuristic algorithms;Brain modeling;Radar tracking;Dynamic programming;Complexity theory;Perception;Control systems;Cognitive dyanamic systems;cognitive control;dynamic programming;two-state model;entropic state;Shannon's entropy;explore/exploit tradeoff;learning;planning;Bayesian filtering},
  doi={10.1109/ACCESS.2014.2332333},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6113213,
  author={Yuen, Man-Ching and King, Irwin and Leung, Kwong-Sak},
  booktitle={2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing}, 
  title={A Survey of Crowdsourcing Systems}, 
  year={2011},
  volume={},
  number={},
  pages={766-773},
  abstract={Crowd sourcing is evolving as a distributed problem-solving and business production model in recent years. In crowd sourcing paradigm, tasks are distributed to networked people to complete such that a company's production cost can be greatly reduced. In 2003, Luis von Ahn and his colleagues pioneered the concept of "human computation", which utilizes human abilities to perform computation tasks that are difficult for computers to process. Later, the term "crowdsourcing" was coined by Jeff Howe in 2006. Since then, a lot of work in crowd sourcing has focused on different aspects of crowd sourcing, such as computational techniques and performance analysis. In this paper, we give a survey on the literature on crowd sourcing which are categorized according to their applications, algorithms, performances and datasets. This paper provides a structured view of the research on crowd sourcing to date.},
  keywords={Humans;Games;Production;Internet;Algorithm design and analysis;Computers;Encyclopedias;crowdsourcing;survey},
  doi={10.1109/PASSAT/SocialCom.2011.203},
  ISSN={},
  month={Oct},}@ARTICLE{8839118,
  author={Jacob, Sunil and Menon, Varun G. and Al-Turjman, Fadi and P. G., Vinoj and Mostarda, Leonardo},
  journal={IEEE Access}, 
  title={Artificial Muscle Intelligence System With Deep Learning for Post-Stroke Assistance and Rehabilitation}, 
  year={2019},
  volume={7},
  number={},
  pages={133463-133473},
  abstract={Stroke is one of the prime reasons for paralysis throughout the world caused due to impaired nervous system and resulting in disability to move the affected body parts. Rehabilitation is the natural remedy for recovering from paralysis and enhancing the quality of life. Brain Computer Interface (BCI) controlled assistive technology is the new paradigm, providing assistance and rehabilitation for the paralysed. But, most of these devices are error prone and also hard to get continuous control because of the dynamic nature of the brain signals. Moreover, existing devices like exoskeletons brings additional burden on the patient and the caregivers and also results in mental fatigue and frustration. To solve these issues Artificial Muscle Intelligence with Deep Learning (AMIDL) system is proposed in this paper. AMIDL integrates user intentions with artificial muscle movements in an efficient way to improve the performance. Human thoughts captured using Electroencephalogram (EEG) sensors are transformed into body movements, by utilising microcontroller and Transcutaneous Electrical Nerve Stimulation (TENS) device. EEG signals are subjected to pre-processing, feature extraction and classification, before being passed on to the affected body part. The received EEG signal is correlated with the recorded artificial muscle movements. If the captured EEG signal falls below the desired level, the affected body part will be stimulated by the recorded artificial muscle movements. The system also provides a feature for communicating human intentions as alert message to caregivers, in case of emergency situations. This is achieved by offline training of specific gesture and online gesture recognition algorithm. The recognised gesture is transformed into speech, thus enabling the paralysed to express their feelings to the relatives or friends. Experiments were carried out with the aid of healthy and paralysed subjects. The AMIDL system helped to reduce mental fatigue, miss-operation, frustration and provided continuous control. The thrust of lifting the exoskeleton is also reduced by using light weight wireless electrodes. The proposed system will be a great communication aid for paralysed to express their thoughts and feelings with dear and near ones, thereby enhancing the quality of life.},
  keywords={Electroencephalography;Exoskeletons;Muscles;Robot kinematics;Robot sensing systems;Task analysis;Artificial muscle intelligence;assistivetechnologies;BCI;EEG;exoskeleton;healthcare;intelligent solutions;deep learning system;paralyzed;stroke},
  doi={10.1109/ACCESS.2019.2941491},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6014716,
  author={Sabahi, Farzad},
  booktitle={2011 IEEE 3rd International Conference on Communication Software and Networks}, 
  title={Virtualization-level security in cloud computing}, 
  year={2011},
  volume={},
  number={},
  pages={250-254},
  abstract={Cloud computing is one of today's most exciting technology because of its cost-reducing, flexibility, and scalability. With the fast growing of cloud computing technology, Data security becomes more and more important in it. In evaluating whether to move to cloud computing, it is important to compare benefits and also risks of it. Thus, security and other existed issues in the cloud cause cloud clients need more time to think about moving to cloud environments. But Security-related topics is one of the most arguable issues in the cloud computing which caused several enterprises looks to this technology uncertainly and move toward it warily. In this paper I try to summarize cloud computing RAS (Reliability, Availability, and Security) issues and also clarify available solution for some of them. In this paper I try to summarize virtualization level of cloud computing security in detailed view.},
  keywords={Privacy;Computational modeling;Business;Reliability;Virtual machine monitors;Security;Virtualization;Cloud computing;Security},
  doi={10.1109/ICCSN.2011.6014716},
  ISSN={},
  month={May},}@ARTICLE{9756272,
  author={Cao, Longbing},
  journal={IEEE Intelligent Systems}, 
  title={A New Age of AI: Features and Futures}, 
  year={2022},
  volume={37},
  number={1},
  pages={25-37},
  abstract={By reviewing the 70 years of AI, this article summarizes and discusses the paradigm transformations from the age of AI before the year 2000 to the new age of AI from the year 2000 onward. It reviews the AI thinking and features of various AI generations and paradigms during these two ages of AI and their transformations. The paper further summarizes several AI Formulas from the AI vision, system, goal, task, and process perspectives. Several important areas are highlighted in developing AI Futures: shrinking the gaps between human, natural and social AI, and developing human-like/level AI, meta AI, reflective AI, metasynthetic AI, data-driven AI, beyond ‘IID AI,’ actionable AI, and sustainable AI. In the new age of AI, we encourage your deep thinking of AI futures.},
  keywords={Machine vision;Artificial intelligence;Technology forecasting;Intelligent systems},
  doi={10.1109/MIS.2022.3150944},
  ISSN={1941-1294},
  month={Jan},}@ARTICLE{10602503,
  author={Kalateh, Sepideh and Estrada-Jimenez, Luis A. and Nikghadam-Hojjati, Sanaz and Barata, Jose},
  journal={IEEE Access}, 
  title={A Systematic Review on Multimodal Emotion Recognition: Building Blocks, Current State, Applications, and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={103976-104019},
  abstract={Emotion recognition involves accurately interpreting human emotions from various sources and modalities, including questionnaires, verbal, and physiological signals. With its broad applications in affective computing, computational creativity, human-robot interactions, and market research, the field has seen a surge in interest in recent years. This paper presents a systematic review of multimodal emotion recognition (MER) techniques developed from 2014 to 2024, encompassing verbal, physiological signals, facial, body gesture, and speech as well as emerging methods like sketches emotion recognition. The review explores various emotion models, distinguishing between emotions, feelings, sentiments, and moods, along with human emotional expression, categorized in both artistic and non-verbal ways. It also discusses the background of automated emotion recognition systems and introduces seven criteria for evaluating modalities alongside a current state analysis of MER, drawn from the human-centric perspective of this field. By selecting the PRISMA guidelines and carefully analyzing 45 selected articles, this review provides comprehensive perspectives into existing studies, datasets, technical approaches, identified gaps, and future directions in MER. It also highlights existing challenges and current applications of the MER.},
  keywords={Emotion recognition;Physiology;Mood;Feature extraction;Cultural differences;Guidelines;Multimodal sensors;Artificial intelligence;Affective computing;Deep learning;Machine learning;Multimodal emotion recognition;artificial intelligence;affective computing;emotion recognition;deep learning;machine learning;emotion expression},
  doi={10.1109/ACCESS.2024.3430850},
  ISSN={2169-3536},
  month={},}@ARTICLE{8951014,
  author={Khan, Irfan and Zhang, Xianchao and Rehman, Mobashar and Ali, Rahman},
  journal={IEEE Access}, 
  title={A Literature Survey and Empirical Study of Meta-Learning for Classifier Selection}, 
  year={2020},
  volume={8},
  number={},
  pages={10262-10281},
  abstract={Classification is the key and most widely studied paradigm in machine learning community. The selection of appropriate classification algorithm for a particular problem is a challenging task, formally known as algorithm selection problem (ASP) in literature. It is increasingly becoming focus of research in machine learning community. Meta-learning has demonstrated substantial success in solving ASP, especially in the domain of classification. Considerable progress has been made in classification algorithm recommendation and researchers have proposed various methods in literature that tackles ASP in many different ways in meta-learning setup. Yet there is a lack of survey and comparative study that critically analyze, summarize and assess the performance of existing methods. To fill these gaps, in this paper we first present a literature survey of classification algorithm recommendation methods. The survey shed light on the motivational reasons for pursuing classifier selection through meta-learning and comprehensively discusses the different phases of classifier selection based on a generic framework that is formed as an outcome of reviewing prior works. Subsequently, we critically analyzed and summarized the existing studies from the literature in three important dimensions i.e., meta-features, meta-learner and meta-target. In the second part of this paper, we present extensive comparative evaluation of all the prominent methods for classifier selection based on 17 classification algorithms and 84 benchmark datasets. The comparative study quantitatively assesses the performance of classifier selection methods and highlight the limitations and strengths of meta-features, meta-learners and meta-target in classification algorithm recommendation system. Finally, we conclude this paper by identifying current challenges and suggesting future work directions. We expect that this work will provide baseline and a solid overview of state of the art works in this domain to new researchers, and will steer future research in this direction.},
  keywords={Machine learning algorithms;Task analysis;Classification algorithms;Machine learning;Heuristic algorithms;Clustering algorithms;Space exploration;Meta-learning;algorithm selection;classification;machine learning},
  doi={10.1109/ACCESS.2020.2964726},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9138986,
  author={Abts, Dennis and Ross, Jonathan and Sparling, Jonathan and Wong-VanHaren, Mark and Baker, Max and Hawkins, Tom and Bell, Andrew and Thompson, John and Kahsai, Temesghen and Kimmell, Garrin and Hwang, Jennifer and Leslie-Hurd, Rebekah and Bye, Michael and Creswick, E.R. and Boyd, Matthew and Venigalla, Mahitha and Laforge, Evan and Purdy, Jon and Kamath, Purushotham and Maheshwari, Dinesh and Beidler, Michael and Rosseel, Geert and Ahmad, Omar and Gagarin, Gleb and Czekalski, Richard and Rane, Ashay and Parmar, Sahil and Werner, Jeff and Sproch, Jim and Macias, Adrian and Kurtz, Brian},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep Learning Workloads}, 
  year={2020},
  volume={},
  number={},
  pages={145-158},
  abstract={In this paper, we introduce the Tensor Streaming Processor (TSP) architecture, a functionally-sliced microarchitecture with memory units interleaved with vector and matrix deep learning functional units in order to take advantage of dataflow locality of deep learning operations. The TSP is built based on two key observations: (1) machine learning workloads exhibit abundant data parallelism, which can be readily mapped to tensors in hardware, and (2) a simple and deterministic processor with producer-consumer stream programming model enables precise reasoning and control of hardware components, achieving good performance and power efficiency. The TSP is designed to exploit parallelism inherent in machine-learning workloads including instruction-level, memory concurrency, data and model parallelism, while guaranteeing determinism by eliminating all reactive elements in the hardware (e.g. arbiters, and caches). Early ResNet50 image classification results demonstrate 20.4K processed images per second (IPS) with a batch-size of one— a $4 \times$ improvement compared to other modern GPUs and accelerators [44]. Our first ASIC implementation of the TSP architecture yields a computational density of more than 1 TeraOp/s per square mm of silicon for its $25 \times 29$ mm 14nm chip operating at a nominal clock frequency of 900 MHz. The TSP demonstrates a novel hardware-software approach to achieve fast, yet predictable, performance on machine-learning workloads within a desired power envelope.},
  keywords={},
  doi={10.1109/ISCA45697.2020.00023},
  ISSN={},
  month={May},}@ARTICLE{8951256,
  author={Chakraborty, Koyel and Bhattacharyya, Siddhartha and Bag, Rajib},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={A Survey of Sentiment Analysis from Social Media Data}, 
  year={2020},
  volume={7},
  number={2},
  pages={450-464},
  abstract={In the current era of automation, machines are constantly being channelized to provide accurate interpretations of what people express on social media. The human race nowadays is submerged in the idea of what and how people think and the decisions taken thereafter are mostly based on the drift of the masses on social platforms. This article provides a multifaceted insight into the evolution of sentiment analysis into the limelight through the sudden explosion of plethora of data on the internet. This article also addresses the process of capturing data from social media over the years along with the similarity detection based on similar choices of the users in social networks. The techniques of communalizing user data have also been surveyed in this article. Data, in its different forms, have also been analyzed and presented as a part of survey in this article. Other than this, the methods of evaluating sentiments have been studied, categorized, and compared, and the limitations exposed in the hope that this shall provide scope for better research in the future.},
  keywords={Social networking (online);Sentiment analysis;Clustering algorithms;Indexes;Computer science;Tools;Business;Clustering;community;sentiment analysis;social media;social networks},
  doi={10.1109/TCSS.2019.2956957},
  ISSN={2329-924X},
  month={April},}@ARTICLE{8449329,
  author={Wang, Shuai and Wang, Jing and Wang, Xiao and Qiu, Tianyu and Yuan, Yong and Ouyang, Liwei and Guo, Yuanyuan and Wang, Fei-Yue},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Blockchain-Powered Parallel Healthcare Systems Based on the ACP Approach}, 
  year={2018},
  volume={5},
  number={4},
  pages={942-950},
  abstract={To improve the accuracy of diagnosis and the effectiveness of treatment, a framework of parallel healthcare systems (PHSs) based on the artificial systems + computational experiments + parallel execution (ACP) approach is proposed in this paper. PHS uses artificial healthcare systems to model and represent patients’ conditions, diagnosis, and treatment process, then applies computational experiments to analyze and evaluate various therapeutic regimens, and implements parallel execution for decision-making support and real-time optimization in both actual and artificial healthcare processes. In addition, we combine the emerging blockchain technology with PHS, via constructing a consortium blockchain linking patients, hospitals, health bureaus, and healthcare communities for comprehensive healthcare data sharing, medical records review, and care auditability. Finally, a prototype named parallel gout diagnosis and treatment system is built and deployed to verify and demonstrate the effectiveness and efficiency of the blockchain-powered PHS framework.},
  keywords={Medical diagnosis;Blockchain;Parallel processing;Smart healthcare;Medical treatment;Artificial systems + computational experiments + parallel execution (ACP);blockchain;parallel healthcare systems (PHSs);parallel intelligence;smart medicine},
  doi={10.1109/TCSS.2018.2865526},
  ISSN={2329-924X},
  month={Dec},}@INPROCEEDINGS{8252094,
  author={Ahmad, Adang Suwandi and Sumari, Arwin Datumaya Wahyudi},
  booktitle={2017 Computing Conference}, 
  title={Cognitive artificial intelligence: Brain-inspired intelligent computation in artificial intelligence}, 
  year={2017},
  volume={},
  number={},
  pages={135-141},
  abstract={Computation occurred within human brain is very much awesome and is not possible to be emulated 100% exactly in Artificial Intelligence (AI) method-based machines. What scientists did and have been done so far up to now are to try to model it as close as to what exactly occurs within the brain. Human brain has an awesome mechanism in performing computation with the end result is new knowledge and human uses the knowledge to actuate his organs. In this paper we will show a new approach for emulating the computation occured within human brain to obtain new knowledge based on the inputs sensed by the system's sensory system taken from the environment. When this process is carried out recursively, the system's knowledge becomes newer and newer, and it is called as knowledge growing. This approach is designed for an agent that has ability to think and act rationally like human. Our cognitive modelling approach is resulted in a model of human information processing and a technique to obtain the most maximum performance should be taken by the cognitive agent. This method is called as A3S (Arwin-Adang-Aciek-Sembiring), the agent is called as Knowledge-Growing System (KGS) and this brain-inspired method opens a new perspective in AI that we call as Cognitive Artificial Intelligence (CAI).},
  keywords={Brain modeling;Information processing;Artificial intelligence;Mathematical model;Psychology;Computational modeling;A3S;Cognitive Artificial Intelligence;intelligent computation;knowledge extraction;Knowledge-Growing System},
  doi={10.1109/SAI.2017.8252094},
  ISSN={},
  month={July},}@INPROCEEDINGS{990497,
  author={Bertalmio, M. and Bertozzi, A.L. and Sapiro, G.},
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
  title={Navier-stokes, fluid dynamics, and image and video inpainting}, 
  year={2001},
  volume={1},
  number={},
  pages={I-I},
  abstract={Image inpainting involves filling in part of an image or video using information from the surrounding area. Applications include the restoration of damaged photographs and movies and the removal of selected objects. We introduce a class of automated methods for digital inpainting. The approach uses ideas from classical fluid dynamics to propagate isophote lines continuously from the exterior into the region to be inpainted. The main idea is to think of the image intensity as a 'stream function for a two-dimensional incompressible flow. The Laplacian of the image intensity plays the role of the vorticity of the fluid; it is transported into the region to be inpainted by a vector field defined by the stream function. The resulting algorithm is designed to continue isophotes while matching gradient vectors at the boundary of the inpainting region. The method is directly based on the Navier-Stokes equations for fluid dynamics, which has the immediate advantage of well-developed theoretical and numerical results. This is a new approach for introducing ideas from computational fluid dynamics into problems in computer vision and image analysis.},
  keywords={Fluid dynamics;Streaming media;Filling;Image restoration;Motion pictures;Laplace equations;Algorithm design and analysis;Navier-Stokes equations;Computational fluid dynamics;Computer vision},
  doi={10.1109/CVPR.2001.990497},
  ISSN={1063-6919},
  month={Dec},}@ARTICLE{9199553,
  author={Ji, Shaoxiong and Pan, Shirui and Li, Xue and Cambria, Erik and Long, Guodong and Huang, Zi},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Suicidal Ideation Detection: A Review of Machine Learning Methods and Applications}, 
  year={2021},
  volume={8},
  number={1},
  pages={214-226},
  abstract={Suicide is a critical issue in modern society. Early detection and prevention of suicide attempts should be addressed to save people's life. Current suicidal ideation detection (SID) methods include clinical methods based on the interaction between social workers or experts and the targeted individuals and machine learning techniques with feature engineering or deep learning for automatic detection based on online social contents. This article is the first survey that comprehensively introduces and discusses the methods from these categories. Domain-specific applications of SID are reviewed according to their data sources, i.e., questionnaires, electronic health records, suicide notes, and online user content. Several specific tasks and data sets are introduced and summarized to facilitate further research. Finally, we summarize the limitations of current work and provide an outlook of further research directions.},
  keywords={Feature extraction;Machine learning;Psychology;Twitter;Task analysis;Deep learning;feature engineering;social content;suicidal ideation detection (SID)},
  doi={10.1109/TCSS.2020.3021467},
  ISSN={2329-924X},
  month={Feb},}@ARTICLE{10506064,
  author={Li, Xiang and Wen, Congcong and Hu, Yuan and Yuan, Zhenghang and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={Vision-Language Models in Remote Sensing: Current progress and future trends}, 
  year={2024},
  volume={12},
  number={2},
  pages={32-66},
  abstract={The remarkable achievements of ChatGPT and Generative Pre-trained Transformer 4 (GPT-4) have sparked a wave of interest and research in the field of large language models (LLMs) for artificial general intelligence (AGI). These models provide intelligent solutions that are closer to human thinking, enabling us to use general artificial intelligence (AI) to solve problems in various applications. However, in the field of remote sensing (RS), the scientific literature on the implementation of AGI remains relatively scant. Existing AI-related research in RS focuses primarily on visual-understanding tasks while neglecting the semantic understanding of the objects and their relationships. This is where vision-LMs (VLMs) excel as they enable reasoning about images and their associated textual descriptions, allowing for a deeper understanding of the underlying semantics. VLMs can go beyond visual recognition of RS images and can model semantic relationships as well as generate natural language descriptions of the image. This makes them better suited for tasks that require both visual and textual understanding, such as image captioning and visual question answering (VQA). This article provides a comprehensive review of the research on VLMs in RS, summarizing the latest progress, highlighting current challenges, and identifying potential research opportunities. Specifically, we review the application of VLMs in mainstream RS tasks, including image captioning, text-based image generation, text-based image retrieval (TBIR), VQA, scene classification, semantic segmentation, and object detection. For each task, we analyze representative works and discuss research progress. Finally, we summarize the limitations of existing works and provide possible directions for future development. This review aims to provide a comprehensive overview of the current research progress of VLMs in RS (see Figure 1), and to inspire further research in this exciting and promising field.},
  keywords={Task analysis;Visualization;Transformers;Computational modeling;Feature extraction;Chatbots;Semantics;Visual analytics;Communication systems},
  doi={10.1109/MGRS.2024.3383473},
  ISSN={2168-6831},
  month={June},}@ARTICLE{4503259,
  author={Licklider, J. C. R.},
  journal={IRE Transactions on Human Factors in Electronics}, 
  title={Man-Computer Symbiosis}, 
  year={1960},
  volume={HFE-1},
  number={1},
  pages={4-11},
  abstract={Man-computer symbiosis is an expected development in cooperative interaction between men and electronic computers. It will involve very close coupling between the human and the electronic members of the partnership. The main aims are 1) to let computers facilitate formulative thinking as they now facilitate the solution of formulated problems, and 2) to enable men and computers to cooperate in making decisions and controlling complex situations without inflexible dependence on predetermined programs. In the anticipated symbiotic partnership, men will set the goals, formulate the hypotheses, determine the criteria, and perform the evaluations. Computing machines will do the routinizable work that must be done to prepare the way for insights and decisions in technical and scientific thinking. Preliminary analyses indicate that the symbiotic partnership will perform intellectual operations much more effectively than man alone can perform them. Prerequisites for the achievement of the effective, cooperative association include developments in computer time sharing, in memory components, in memory organization, in programming languages, and in input and output equipment.},
  keywords={Symbiosis;Insects;Time sharing computer systems;Performance evaluation;Performance analysis;Computer languages},
  doi={10.1109/THFE2.1960.4503259},
  ISSN={2168-2836},
  month={March},}@ARTICLE{10577164,
  author={Hang, Ching Nam and Wei Tan, Chee and Yu, Pei-Duo},
  journal={IEEE Access}, 
  title={MCQGen: A Large Language Model-Driven MCQ Generator for Personalized Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={102261-102273},
  abstract={In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.},
  keywords={Education;Knowledge engineering;Testing;Knowledge based systems;Task analysis;Semantics;Problem-solving;Large language models;Information retrieval;Data augmentation;Large language models;multiple-choice questions;personalized learning;prompt engineering;retrieval-augmented generation},
  doi={10.1109/ACCESS.2024.3420709},
  ISSN={2169-3536},
  month={},}@ARTICLE{933500,
  author={Buttazzo, G.},
  journal={Computer}, 
  title={Artificial consciousness: Utopia or real possibility?}, 
  year={2001},
  volume={34},
  number={7},
  pages={24-30},
  abstract={Since the beginnings of computer technology, researchers have speculated about the possibility of building smart machines that could compete with human intelligence. Given the current pace of advances in artificial intelligence and neural computing, such an evolution seems to be a more concrete possibility. Many people now believe that artificial consciousness is possible and that, in the future, it will emerge in complex computing machines. However, a discussion of artificial consciousness gives rise to several philosophical issues: can computers think or do they just calculate? Is consciousness a human prerogative? Does consciousness depend on the material that comprises the human brain, or can computer hardware replicate consciousness? Answering these questions is difficult because it requires combining information from many disciplines including computer science, neurophysiology, philosophy, and religion. Further, we must consider the influence of science fiction, especially science fiction films, when addressing artificial consciousness. As a product of the human imagination, such works express human desires and fears about future technologies and may influence the course of progress. At a societal level, science fiction simulates future scenarios that can help prepare us for crucial transitions by predicting the consequences of significant technological advances. The paper considers robots in science fiction, the Turing test, computer chess and artificial consciousness.},
  keywords={Humans;Artificial intelligence;Intelligent structures;Machine intelligence;Concrete;Hardware;Computer science;Neurophysiology;Computational modeling;Predictive models},
  doi={10.1109/2.933500},
  ISSN={1558-0814},
  month={July},}@ARTICLE{9749967,
  author={Herrero-Álvarez, Rafael and Miranda, Gara and León, Coromoto and Segredo, Eduardo},
  journal={IEEE Transactions on Emerging Topics in Computing}, 
  title={Engaging Primary and Secondary School Students in Computer Science Through Computational Thinking Training}, 
  year={2023},
  volume={11},
  number={1},
  pages={56-69},
  abstract={Although Computer Science has grown to become one of the most highly demanded professional careers, every year, only a small percentage of students choose a degree directly related to Computer Science. Perhaps the problem lies in the lack of information that society has about Computer Science itself, and particularly about the work computer scientists do. No one doubts the role of Mathematics or Languages as core subjects in every primary and secondary education syllabus; however, Computer Science plays a negligible role in most current syllabuses. Only in a few countries have governments paid special attention to content related to Computer Science and to learning to analyze and solve problems the way computer scientists do (Computational Thinking). In this article, we present Piens@ Computacion@ULLmente, a project that provides a methodology to promote Computer Science through Computational Thinking activities among primary and secondary education students. The results obtained from an exhaustive statistical analysis of the data we collected demonstrate that the perception of Computer Science that pre-university students have can be improved through specific training. Moreover, we can also confirm that the performance of pre-university students involving Computational Thinking skills is independent of gender, particularly at the primary education level.},
  keywords={Computer science;Training;Problem-solving;Programming profession;Engineering profession;Licenses;Europe;Computer science;computational thinking;primary education;secondary education;syllabus},
  doi={10.1109/TETC.2022.3163650},
  ISSN={2168-6750},
  month={Jan},}@INPROCEEDINGS{7738674,
  author={Agrawal, Ankur and Choi, Jungwook and Gopalakrishnan, Kailash and Gupta, Suyog and Nair, Ravi and Oh, Jinwook and Prener, Daniel A. and Shukla, Sunil and Srinivasan, Vijayalakshmi and Sura, Zehra},
  booktitle={2016 IEEE International Conference on Rebooting Computing (ICRC)}, 
  title={Approximate computing: Challenges and opportunities}, 
  year={2016},
  volume={},
  number={},
  pages={1-8},
  abstract={Approximate computing is gaining traction as a computing paradigm for data analytics and cognitive applications that aim to extract deep insight from vast quantities of data. In this paper, we demonstrate that multiple approximation techniques can be applied to applications in these domains and can be further combined together to compound their benefits. In assessing the potential of approximation in these applications, we took the liberty of changing multiple layers of the system stack: architecture, programming model, and algorithms. Across a set of applications spanning the domains of DSP, robotics, and machine learning, we show that hot loops in the applications can be perforated by an average of 50% with proportional reduction in execution time, while still producing acceptable quality of results. In addition, the width of the data used in the computation can be reduced to 10-16 bits from the currently common 32/64 bits with potential for significant performance and energy benefits. For parallel applications we reduced execution time by 50% using relaxed synchronization mechanisms. Finally, our results also demonstrate that benefits compounded when these techniques are applied concurrently. Our results across different applications demonstrate that approximate computing is a widely applicable paradigm with potential for compounded benefits from applying multiple techniques across the system stack. In order to exploit these benefits it is essential to re-think multiple layers of the system stack to embrace approximations ground-up and to design tightly integrated approximate accelerators. Doing so will enable moving the applications into a world in which the architecture, programming model, and even the algorithms used to implement the application are all fundamentally designed for approximate computing.},
  keywords={Approximate computing;Synchronization;Hardware;Computer architecture;Synthetic aperture radar;Training;Approximation algorithms;Approximate computing;perforation;reduced precision;relaxed synchronization},
  doi={10.1109/ICRC.2016.7738674},
  ISSN={},
  month={Oct},}@ARTICLE{9741843,
  author={Rijo-García, Sara and Segredo, Eduardo and León, Coromoto},
  journal={IEEE Transactions on Education}, 
  title={Computational Thinking and User Interfaces: A Systematic Review}, 
  year={2022},
  volume={65},
  number={4},
  pages={647-656},
  abstract={Contribution: This document presents a systematic bibliographic review that demonstrates the need to conduct research on how the user experience impacts the development of computational thinking. Background: In the field of computer science, computational thinking is defined as a method that enhances problem-solving skills, system design, and human behavior understanding. Over the last few decades, several tools have been proposed for the development of computational thinking skills; however, there is no area of study that evaluates the implications or the impact that these types of platforms have on users belonging to any knowledge area. Research Question: Do user interfaces influence the development of computational thinking skills? Methodology: To address this issue, a systematic review of the literature was conducted using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) methodology for analyzing and evaluating scientific publications. Findings: The results show that despite the dearth of literature on the subject, the specific design of a user interface has a significant impact on the development of computational thinking. Bearing the above in mind, it is necessary to conduct research that delves more deeply into the effects caused by the technologies that are used to develop computational thinking, this being a line of research that is worthy of consideration.},
  keywords={User interfaces;Systematics;User experience;Usability;Programming profession;Computational modeling;Libraries;Computational thinking;human–computer interaction;preferred reporting items for systematic reviews and meta-analyses (PRISMA);survey;systematic review;usability;user experience;user interface;visual programming},
  doi={10.1109/TE.2022.3159765},
  ISSN={1557-9638},
  month={Nov},}
